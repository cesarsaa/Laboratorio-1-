%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Plantilla: para la realizaci�n de informes.
%Curso:     Simulaci�n estad�stica.
%Profesor:  Johann A. Ospina.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%Establece el tipo de documento (art�culo), tama�o de letra (10pt) a una columna.
\documentclass[letterpaper,12pt,onecolumn,titlepage]{article} 
 
 
% Cargar paquetes
\usepackage{verbatim}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{ucs}
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel}
\usepackage{fontenc}
\usepackage{graphicx}
\usepackage{anysize}
\usepackage{fancyhdr}
\usepackage[comma,authoryear]{natbib}
\usepackage{url} %paquete para definir url
\usepackage{hyperref}  %hipervinculos

%Estilo de la p�gina
\pagestyle{fancy}

%Establecer el margen
\marginsize{2cm}{2cm}{1cm}{1cm}
\setlength{\headheight}{13.1pt}


% Portada
\title{
    \textbf{Laboratorio N.1}\
    ~\\{Introduccion a Los Metodos Estadisticos}   
    ~\\{Estimadores}}
\author{
    {Diana Carolina Arias Sinisterra Cod. 1528008}
 ~\\{Kevin Steven Garcia Chica Cod. 1533173}
 ~\\{Cesar Andres Saavedra Vanegas Cod. 1628466}}

\date{
     \textbf{Universidad Del Valle}\   
    ~\\{Facultad De Ingenieria}
    ~\\{Estadistica}
    ~\\{Octubre}
    ~\\{2017}}
 
 
 
\decimalpoint %Poner punto decimal
 
\begin{document}
 
% Se aplica el formato a las p�ginas. Se despliegan: portada e �ndices de materias, figuras y tablas
\renewcommand{\listtablename}{Indice de tablas}
\renewcommand{\tablename}{Tabla}
\maketitle
\setcounter{page}{2}
\tableofcontents{}
%\thispagestyle{empty}
%\newpage
\listoffigures{}
\listoftables

\thispagestyle{empty}

\newpage
\fancyhead{}
\fancyfoot{}
 
% Encabezado y pie de pagina
\lhead{Introduccion a los Metodos Estadisticos}
\lfoot{Universidad Del Valle}
\rfoot{\thepage}

% Estilo de la bibliograf�a
\bibliographystyle{apalike}
 
% Desarrollo de los contenidos del documento
\section{Situacion 1}
\subsection{Estimadores}
~\\ Los estimadores propuestos son:
~\ $$\hat{\theta_1}=2\bar{X}-1$$
~\ $$\hat{\theta_2}=X_{Max}+X_{Min}-1$$
~\ $$\hat{\theta_3}=X_{Max}$$
~\ $$\hat{\theta_4}=Me(X) $$
~\\ Para evaluar los estimadores anteriores obtuvimos las siguientes cuatro graficas:
\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=10cm]{Figuras/A.png}
        \caption{Grafica del resultado de la estimacion del parametro real $\theta=1200$}
        \label{fig:Densidad}
    \end{center}
\end{figure}
~\\ Como podemos observar en la grafica,los estimadores $\hat{\theta_1}$ y $\hat{\theta_2}$ son los que mas se acercan al parametro real $\theta=1200$  con cualquier tama\~{n}o de muestra, aunque el estimador $\hat{\theta_3}$ tambien se acerca pero despues de tama\~{n}o de muestra $n=100$, lo cual nos dice que son mejores los dos anteriores. El estimador $\hat{\theta_4}$ esta muy lejos del parametro real, a simple vista podriamos decir que ese estimador serviria no para estimar $\theta$ en si, si no, para estimar la media de la distribucion en general que es aproximadamente 600.
\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=10cm]{Figuras/S.png}
        \caption{Grafica del sesgo de los distintos estimadores variando los tama\~{n}os de muestra}
        \label{fig:Densidad}
    \end{center}
\end{figure}
~\\ En esta grafica vemos que al igual que en la anterior, los estimadores $\hat{\theta_1}$ y $\hat{\theta_2}$ son los mejores, ya que tienen un sesgo casi igual a 0 para todos los tama\~{n}os de muestra, aunque vemos tambien que el sesgo del estimador $\hat{\theta_3}$ tambien tiende a 0 a medida que se aumenta los tama\~{n}os de muestra. El estimador $\hat{\theta_4}$ es el menos acertado ya que su sesgo es muy elevado. En general, basandonos en esta grafica, los mejores estimadores hasta ahora son $\hat{\theta_1}$ y $\hat{\theta_2}$
\pagebreak \begin{figure}[!h]
    \begin{center}
        \includegraphics[width=10cm]{Figuras/V.png}
        \caption{Grafica de la varianza de los distintos estimadores variando los tama\~{n}os de muestra}
        \label{fig:Densidad}
    \end{center}
\end{figure}
~\\ En esta grafica podemos observar que los estimadores $\hat{\theta_2}$ y $\hat{\theta_3}$ tienen menor varianza que los otros dos, pero notemos, que la diferencia de varianzas entre $\hat{\theta_2}$ y $\hat{\theta_3}$ es casi la mitad a favor de $\hat{\theta_3}$ en los tama\~{n}os de muestra mas peque\~{n}os, indicandonos esto, que el estimador de menor varianza es efectivamente $\hat{\theta_3}$.
\pagebreak \begin{figure}[!h]
    \begin{center}
        \includegraphics[width=10cm]{Figuras/ECM.png}
        \caption{Grafica del ECM de los distintos estimadores variando los tama\~{n}os de muestra}
        \label{fig:Densidad}
    \end{center}
\end{figure}
~\\ En la grafica anterior, notamos que el menor Error cuadratico medio lo presentan los estimadores $\hat{\theta_2}$ y $\hat{\theta_3}$, con casi el mismo en todos los tama\~{n}os de muestra, por esa razon no logramos ver la linea y los puntos que representan el estimador $\hat{\theta_2}$, pero en el tama\~{n}o de muestra n=5 se alcanza a observar una peque\~{n}a porcion del punto rojo que representa el estimador $\hat{\theta_2}$, obstruido por el punto verde que representa el estimador $\hat{\theta_3}$, lo que nos asegura que no hay diferencias significativas entre estos estimadores con respecto al ECM.Entonces, para decidir cual de los dos estimadores es mejor, debemos ver las 4 graficas en conjunto, ya que el ECM no me deja claro esto, por ser tan parecido en ambos.

~\\ En conclusion, tomando en cuenta las 4 graficas, podriamos decir que para tama\~{n}os de muestra menor a 100, $\hat{\theta_2}$ es el mejor estimador para $\theta=1200$ ya que su sesgo es menor que el de $\hat{\theta_3}$, su estimacion es mas cercana al valor real del parametro y ademas su varianza no es muy alta. 


\pagebreak \section{Situacion 2}
\subsection{Punto A.}
~\\\textbf{Si $\hat{\theta_1}$ y $\hat{\theta_2}$ son dos estimadores insesgados tales que:
~\\$$\hat{\theta_3}=a{\hat{\theta_1}}+(1-a){\hat{\theta_2}}$$}
~\\ Aplico Esperanza a ambos lados 
~\\ $E[\hat{\theta_3}] = E[a{\hat{\theta_1}}+(1-a){\hat{\theta_2}}]$
~\\ $E[\hat{\theta_3}] = E[a{\hat{\theta_1}}]+E[(1-a){\hat{\theta_2}}]$
~\\ $E[\hat{\theta_3}] = aE[{\hat{\theta_1}}]+(1-a)E[{\hat{\theta_2}}]$ \textbf{Con $\hat{\theta_1}$ y $\hat{\theta_2}$ estimadores insesgados}\
~\\ $E[\hat{\theta_3}] = a{\theta} + (1-a){\theta}$
~\\ $E[\hat{\theta_3}] = a{\theta} + {\theta} - a{\theta}$
~\\ $$E[\hat{\theta_3}]={\theta}$$

~\\\textbf{$\therefore \hat{\theta_3}$ Es un estimador insesgado.} 
 


\subsection{Punto B.} 

~\\\textbf{ El coeficiente de variacion de $\hat{\theta_3}$ es}
~\\
~\\ $$CV[\hat{\theta_3}]=\frac{\sqrt{Var[\hat{\theta_3}]}}{E[\hat{\theta_3}]}$$
~\\ Hallamos la $Var[\hat{\theta_3}]$
~\\ $Var[\hat{\theta_3}]=Var[a{\hat{\theta_1}}+(1-a){\hat{\theta_2}}]+2Cov[a{\hat{\theta_1}},(1-a){\hat{\theta_2}}]$,    ya que no sabemos si ${\hat{\theta_1}}$ y ${\hat{\theta_2}}$ son independientes
~\\ Entonces, distribuyendo la Varianza y por las propiedades de Covarianza:
~\\ $Var[\hat{\theta_3}]=Var[a{\hat{\theta_1}}]+Var[(1-a){\hat{\theta_2}}]+2a(1-a) Cov[{\hat{\theta_1}},{\hat{\theta_2}}]$
~\\ $Var[\hat{\theta_3}]=a^2Var[{\hat{\theta_1}}]+(1-a)^2Var[{\hat{\theta_2}}]+(2a-2a^2)Cov[{\hat{\theta_1}},{\hat{\theta_2}}]$
~\\
~\\\textbf{Como $Var[{\hat{\theta_1}}]=\sigma_1^2$ y $Var[{\hat{\theta_2}}]=\sigma_2^2$ entonces}

~\\ $Var[\hat{\theta_3}]=a^2[\sigma_1^2]+(1-a)^2[\sigma_2^2]+(2a-2a^2)Cov[{\hat{\theta_1}},{\hat{\theta_2}}]$
~\\ Sabemos que $Cov[{\hat{\theta_1}},{\hat{\theta_2}}]= E[{\hat{\theta_1}}{\hat{\theta_2}}]- E[{\hat{\theta_1}}]*E[{\hat{\theta_2}}]$, entonces:
~\\ Como $E[{\hat{\theta_1}}]={\theta}$ y $E[{\hat{\theta_2}}]={\theta}$ tenemos:
~\\ $Cov[{\hat{\theta_1}},{\hat{\theta_2}}]=E[{\hat{\theta_1}}{\hat{\theta_2}}]-{\theta^2}$, por tanto:
~\\ $Var[\hat{\theta_3}]=a^2[\sigma_1^2]+(1-2a+a^2)[\sigma_2^2]+(2a-2a^2)(E[{\hat{\theta_1}}{\hat{\theta_2}}]-{\theta^2})$
~\\ Como sabemos que $E[\hat{\theta_3}]={\theta}$

~\\$\therefore$ \textbf{El coeficiente de variacion para $\hat{\theta_3}$ es:}  
$$CV[\hat{\theta_3}]=\frac{\sqrt{a^2\sigma_1^2+(1-a)^2\sigma_2^2+(2a-2a^2)(E[{\hat{\theta_1}}{\hat{\theta_2}}]-{\theta^2})}}{{\theta}}$$

\subsection{Punto C.} 
~\\ Como en este punto sabemos que $\hat{\theta_1}$ y $\hat{\theta_2}$ son independientes, entonces la $Cov[{\hat{\theta_1}},{\hat{\theta_2}}]=0$ y por tanto:
~\\ $Var[\hat{\theta_3}]=Var[a{\hat{\theta_1}}+(1-a){\hat{\theta_2}}]$
~\\ Distribuyendo la varianza y aplicando sus propiedades, nos queda:
~\\ $Var[\hat{\theta_3}]=Var[a{\hat{\theta_1}}]+Var[(1-a){\hat{\theta_2}}]$ 
~\\ $Var[\hat{\theta_3}]=a^2Var[{\hat{\theta_1}}]+(1-a)^2Var[{\hat{\theta_2}}]$
~\\ $Var[\hat{\theta_3}]=a^2\sigma_1^2+(1-a)^2\sigma_2^2$ 
~\\ Note que $Var[\hat{\theta_3}]$ se convierte en una funcion que depende de a, ya que, $\sigma_1^2$ y $\sigma_2^2$ son conocidas, entonces, debemos encontrar a, que haga minima dicha funcion, en otras palabras, todo se reduce a encontrar el minimo de la funcion. Para ello procedemos de la siguiente manera:
~\\ 1. Encontramos la primera derivada de la funcion con respecto a la variable a:
~\\ $$f'(a)=2a\sigma_1^2 - 2(1-a)\sigma_2^2$$
~\\ 2. Igualamos el resultado de la primera derivada a 0 y despejamos la variable que nos interesa obtener, en este caso, despejamos a:
$$2a\sigma_1^2 - 2(1-a)\sigma_2^2=0$$
$$2a\sigma_1^2 - (2-2a)\sigma_2^2=0$$
$$2a\sigma_1^2 - 2\sigma_2^2 + 2a\sigma_2^2=0$$
$$2a\sigma_1^2  + 2a\sigma_2^2= 2\sigma_2^2$$
$$a(2\sigma_1^2+2\sigma_2^2)=2\sigma_2^2$$
$$a=\frac{2\sigma_2^2}{2\sigma_1^2+2\sigma_2^2}$$
~\\$\therefore${$a=\frac{\sigma_2^2}{\sigma_1^2+\sigma_2^2}$}
~\\ 3. Ahora, debemos encontrar la segunda derivada y ver si es positiva o negativa para saber si encontramos un minimo o un maximo:
~\\$$f^{\prime\prime}(a)=2\sigma_1^2+2\sigma_2^2 > 0$$
~\\ Como nos dio que la segunda derivada parcial es siempre positiva, concluimos que el a hallado anteriormente es un minimo. Por lo tanto, para hacer que la $Var[\hat{\theta_3}]$ sea minima, debemos escoger a como $a=\frac{\sigma_2^2}{\sigma_1^2+\sigma_2^2}$.

\section{Situacion 3}
\subsection{Punto A.}

Sea $X$ una distribucion Poisson$(\lambda)$ con, $n=30$ y $E[x]=(\lambda)$

$$\ M'_1 = \frac{1}{30} \sum_{i=1}^{30}x_{i}$$
$$\mu'_1 = \lambda$$

$\ M'_1 = \frac{1}{30} \sum_{i=1}^{30}x_{i} = \lambda = \mu'_1$

$\therefore \hat{\lambda}= \frac{1}{30} \sum_{i=1}^{30}x_{i} = \overline{X}$
 
~\\Ahora es necesario probrar si es insesgado: 

~\\$E[\hat{\lambda}]=E[\frac{1}{30} \sum_{i=1}^{30}x_{i}]$
~\\$E[\hat{\lambda}]=\frac{1}{30} E[\sum_{i=1}^{30}{\lambda}_{i}]$
~\\$E[\hat{\lambda}]=\frac{1}{30}30\lambda$
~\\$E[\hat{\lambda}]=\lambda$

~\\$\therefore$ \textbf{Un estimador insesgado para} $\lambda$ \textbf{es} $\hat{\lambda}= \frac{1}{30} \sum_{i=1}^{30}x_{i} = \overline{X}$

\subsection{Punto B.}

Sea $C=3X+X^2$

~\\$E[C]=E[3X+X^2]$
~\\$E[C]=E[3X] + E[X^2]$
~\\$E[C]=3E[X] + E[X^2]$

~\\ Sabiendo que:
 
$V[X]=E[X^2] - E^2[X]$


~\\ Entonces: 

$E^2[X] = V[X] + E[X^2]$

~\\$\therefore E^2[X] = \lambda + (\lambda)^2$

~\\ Reemplazando $E^2[X]$ en:\ 

$E[C]=3\lambda + E[X^2]$

~\\Obtenemos que: 
$E[C]=3\lambda + \lambda + (\lambda)^2$
~\\$\therefore E[C] = 4\lambda + (\lambda)^2$

\subsection{Punto C.}
~\\ Ahora debemos sugerir un estimador insesgado para $E[C] = 4\lambda + {\lambda}^2$
~\\ Como $\hat{\lambda}= \frac{1}{30} \sum_{i=1}^{30}x_{i} = \overline{X}$ es un estimador insesgado para $\lambda$ , creemos que $4\hat{\lambda}+\hat{\lambda}^2$ es insesgado para $E[C] = 4\lambda + {\lambda}^2$
~\\ Para ver si eso es correcto, encontraremos la esperanza del estimador propuesto, y con respecto a ese resultado, transformaremos nuestro estimador para que efectivamente nos de insesgado para $E[C] = 4\lambda + {\lambda}^2$, entonces:
~\\ $$E[4\hat{\lambda}+\hat{\lambda}^2]=E[4\hat{\lambda}]+E[\hat{\lambda}^2]$$
 $$=4E[\hat{\lambda}]+E[\hat{\lambda}^2]$$
~\ reemplazando el valor del estimador en $\hat{\lambda}$, nos queda:
$$=4E[\frac{1}{30}\sum_{i=1}^{30}x_{i}]+E[ \frac{1}{30} \sum_{i=1}^{30}x_{i}]^2$$
$$=\frac{4}{30}E[\sum_{i=1}^{30}x_{i}]+\frac{1}{900}E[\sum_{i=1}^{30}x_{i}]^2$$ 
Denotemos $T=\sum_{i=1}^{30}x_{i}$ . Sabemos que xi tiene distribucion Poisson($\lambda$), por tanto T tendra distribucion Poisson($30\lambda$). Entonces, sustituyendo el T en la ecuacion, tendriamos:
$$=\frac{4}{30}E[T]+\frac{1}{900}E[T]^2$$
Ahora, si T se distribuye Poisson($30\lambda$), entonces $E[T]=30\lambda$ y $V[T]=30\lambda$.
Por propiedades tenemos que $V[T]=E[T^2]-E^2[T]$, entonces, sustituyendo y resolviendo, $E[T^2]=30\lambda-900{\lambda}^2$
Sustituyendo todo en la ecuacion, tenemos lo siguiente:
$$=\frac{4}{30}(30\lambda)+\frac{1}{900}(30\lambda-900{\lambda}^2)$$ 
$$=4\lambda+\frac{1}{30}(\lambda-30{\lambda}^2)$$
$$=4\lambda+\frac{1}{30}\lambda-{\lambda}^2$$
Entonces, debemos modificar nuestro estimador inicial, para que efectivamente su esperanza nos de $4\lambda + {\lambda}^2$
~\\ Note que para obtener esa esperanza solo debemos restar $\frac{1}{30}\lambda$ y cambiarle el signo a $-{\lambda}^2$ al resultado de la esperanza
~\\ Para lograr eso, propusimos el estimador $4\hat{\lambda}-\hat{\lambda}^2+\frac{1}{30}\hat{\lambda}$
~\\ Ahora veremos si este nuevo estimador propuesto si es insesgado para $E[C] = 4\lambda + {\lambda}^2$
$$E[4\hat{\lambda}-\hat{\lambda}^2+\frac{1}{30}\hat{\lambda}]=E[4\hat{\lambda}]-E[\hat{\lambda}^2]+E[\frac{1}{30}\hat{\lambda}]$$
$$=4E[\hat{\lambda}]-E[\hat{\lambda}^2]+\frac{1}{30}E[\hat{\lambda}]$$
Haciendo la misma sustitucion que antes, nos queda:
$$=\frac{4}{30}E[T]-\frac{1}{900}E[T^2]+\frac{1}{900}E[T]$$
$$=\frac{4}{30}(30\lambda)-\frac{1}{900}(30\lambda-900{\lambda}^2)+\frac{1}{900}(30\lambda)$$
$$=4\lambda-\frac{1}{30}(\lambda-30{\lambda}^2)+\frac{1}{30}\lambda$$
$$=4\lambda-\frac{1}{30}\lambda+{\lambda}^2+\frac{1}{30}\lambda$$
$$=4\lambda+{\lambda}^2$$
~\\$\therefore$ \textbf{Un estimador insesgado para} $E[C]=4\lambda+{\lambda}^2$ \textbf{es} $4\hat{\lambda}-\hat{\lambda}^2+\frac{1}{30}\hat{\lambda}$ \textbf{donde:} $\hat{\lambda}=\frac{1}{30} \sum_{i=1}^{30}x_{i} = \overline{X}$
\section{Situacion 4}
\subsection{Punto A.}
~\\Se tiene una poblacion que se encuentra definida por una variable aleatoria X con distribucion Exponencial:

$$\ f(x)=5e^{-5x} ; x>0$$

~\\ Para la cual se generaron 1000 muestras aleatorias de tamano n, para la cual se construyenron histogramas con los valores de las medias y se les sobrepuso la curva normal de parametros $\mu$ y $\frac{\sigma}{\sqrt{n}}$. 

~\\ Esta simulacion se realizo por mdio del software R y para n con tamano de muestra de 5, 10, 20, 30, 50, 100.

\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=15cm]{figuras/4.jpeg}
        \caption{Histograma de frecuencias para una distribucion Exponencial $\lambda=5$}
        \label{fig:Densidad}
    \end{center}
\end{figure}

~\\En la grafica se puede observar claramente como el comportamiento de una funcion Exponencial va cambiando al aumentar el tamano de muestra n hasta llegar a tener el comportamiento de una funcion normal de de parametros $\mu$ y $\frac{\sigma}{\sqrt{n}}$. 
\subsection{Punto B.}
~\\ Para este punto se desea realizar el mismo procedimiento anterior y observar el comportamiento para una distribucion t-Student con 7 grados de libertad.
\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=15cm]{figuras/4b.jpeg}
        \caption{Histograma de frecuencias para una distribucion t-Student con 7 grados de libertad}
        \label{fig:Densidad}
    \end{center}
\end{figure}

\section{Situacion 5}
\subsection{Punto A.}
~\\ Tenemos la siguiente informacion del problema:
~\\ $\mu=3800$  $\sigma=400psi$ $n=4$ y $\bar{X}=3334$ el cual es el valor de la media sobre la cual se toma la decision.
~\\ Para responder a la pregunta sobre el riesgo que corre el proveedor bajo este criterio de decision, decidimos calcular la probabilidad de que $\bar{X}\leq3334$, entonces:
~\\ Sabemos que $\bar{X}\sim{N(\mu_x,\frac{\sigma}{\sqrt{n}}})$, en este caso $\bar{X}\sim{N(\mu_x=3800,\frac{\sigma=400}{\sqrt{4}}})=(\mu_x=3800,\sigma=200)$
~\\Entonces:
~\\ $P(\bar{X}\leq3334)=P(Z\leq\frac{3334-3800}{200})=P(Z\leq\frac{-466}{200})=P(Z\leq-2.33)=0.0099$ (Utilizando la tabla de la normal estandar)
~\\Segun lo anterior, logramos ver que la probabilidad de que la media sea menor que 3344 es tan solo de 0.99\%, entonces concluimos que el riesgo que corre el proveedor de que el cliente les devuelva un lote bajo esta regla de decision es muy bajo, de hecho, segun los resultados, de cada 100 lotes, solo le devolvera uno aproximadamente. El riesgo lo corre mas bien el comprador, ya que este, con la regla de decision establecida no va a lograr concluir casi nunca que el proceso esta fuera de control cuando en realidad lo esta. Por ultimo, viendolo en forma de errores tipo 1 y 2, concluimos que esta regla de decision cuenta con una probabilidad de cometer error tipo 2 muy alta, es decir, la mayoria de veces va a concluir que el proceso esta bajo control, cuando en realidad esta fuera de control.
\subsection{Punto B.}
~\\ Si se cambia la media a $\mu=3700$, la probabilidad que existe de que un lote sea detectado bajo estas condiciones es la siguiente:
~\\ $P(\bar{X}\leq3334)=P(Z\leq\frac{3334-3700}{200})=P(Z\leq\frac{-366}{200})=P(Z\leq-1.83)=0.0336$ (Utilizando la tabla de la normal estandar)
~\\ Con lo anterior, podemos observar que la probabilidad de que un lote sea detectado bajo esas condiciones es de 3.36\%, un poco mas alto que en el punto anterior, esto nos dice que entre mas cerca este $\mu$ del valor de la media muestral $\bar{X}$, mas alta va a ser esta probabilidad, y por consiguiente, las posibilidades de que el cliente detecte el lote van a ser mayores.
\pagebreak \subsection{Punto C.}
\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=10cm]{Figuras/5.png}
        \caption{Grafica de probabilidades de detectar el lote segun la media $\mu$}
        \label{fig:Densidad}
    \end{center}
\end{figure}
~\\ En esta grafica podemos ver que mientras el valor de la media $\mu$ aumenta, la probabilidad de detectar el lote va disminuyendo, esto pasa, porque la resistencia media con la cual se dice que el proceso de produccion esta bajo control es de 3800 psi, entonces a medida que la media muestral aumenta, nos vamos acercando mas a la media teorica (3800 en este caso), lo que hace menos probable que se devuelva un lote de varillas metalicas, ya que mientras mas cercana sea la media muestral a la poblacional, tenemos mas certeza para concluir que las varillas se estan haciendo con el proceso adecuado o bajo control.

\pagebreak \subsection{Punto D.}
~\\ En la grafica que se muestra acontinuacion es posible apreciar la proobabilidad de detectar el lote para k=5 y k=6, para lo cual se muestra la misma tendencia de la grafica anterior y es que a medida que se incrementa la media $\mu$ la probailidad disminuye.
\begin{figure}[!h]
    \begin{center}
        \includegraphics[width=15cm]{Figuras/5d.jpeg}
        \caption{Grafica de probabilidades de detectar el lote para k=5 y k=6}
        \label{fig:Densidad}
    \end{center}
\end{figure}

\section{Scripts}


% Bibliografia utilizada 
\bibliography{Bibliografia}
\end{document}